{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "import keras.utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import keras.regularizers as kr\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import keras.losses as ls\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import sys\n",
    "import math as m\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "%matplotlib qt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Vengono caricati i dati dal file, questa volta non viene fatta nessuna selezione a priori\n",
    "###a parte quella per numero di elementi non nulli.\n",
    "\n",
    "data=pd.read_csv('./Settings/Data/Default/DEFGBData.csv')\n",
    "nancount=[]\n",
    "ind=[]\n",
    "for i in range(0,data.shape[0]):\n",
    "    nancount.append(data.iloc[i,12:].isnull().sum())\n",
    "    if nancount[i]==0:\n",
    "        ind.append(i)\n",
    "    else:\n",
    "        pass\n",
    "data=data.iloc[ind,:]\n",
    "data=data.set_index(['GES_FLD'])\n",
    "\n",
    "data=data.reset_index()   \n",
    "data1=data.values\n",
    "\n",
    "dataset=data.values[:,12:].astype(float)\n",
    "datafei=data.values[:,9].astype(float)\n",
    "dataset=np.nan_to_num(dataset)\n",
    "datafei=np.nan_to_num(datafei)\n",
    "dataset=np.c_[dataset,datafei]\n",
    "\n",
    "asun=[6.24,7.60,6.47,6.34,3.15,3.15,4.95,3.93,5.64,5.64,7.50,7.50,4.99,6.22,2.21]\n",
    "for i in range(0,dataset.shape[0]):\n",
    "    for j in range(0,dataset.shape[1]-1):\n",
    "        if j==10:\n",
    "            pass\n",
    "        else:\n",
    "            dataset[i,j]=(dataset[i,j]-asun[j])-(dataset[i,10]-asun[10])\n",
    "\n",
    "dataset=np.delete(dataset,10,1)\n",
    "invar=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Selezione del target.\n",
    "###Target disponibili: 'NGC2243', 'NGC2420', 'Rup134', 'Trumpler20', 'Trumpler23'\n",
    "target='NGC2243'\n",
    "path=\"./Settings/Weights/target\"\n",
    "path=path.replace('target',target)\n",
    "files=['/gbl0.npy','/gbl0bias.npy','/gbl1.npy','/gbl1bias.npy','/gbl2.npy','/gbl2bias.npy','/gbl3.npy','/gbl3bias.npy']\n",
    "for i in range(len(files)):\n",
    "    files[i]=path+files[i]\n",
    "w0=np.load(files[0])\n",
    "b0=np.load(files[1])\n",
    "w1=np.load(files[2])\n",
    "b1=np.load(files[3])\n",
    "w2=np.load(files[4])\n",
    "b2=np.load(files[5])\n",
    "w3=np.load(files[6])\n",
    "b3=np.load(files[7])\n",
    "\n",
    "path2=\"./Settings/target\"\n",
    "path2=path2.replace('target',target)\n",
    "files2=['/vallossgb.npy','/trainlossgb.npy','/valaccuracygb.npy','/valsetinputgb.npy','/valsetoutputgb.npy','/valindgb.npy']\n",
    "for i in range(len(files2)):\n",
    "    files2[i]=path2+files2[i]\n",
    "valloss=np.load(files2[0])\n",
    "loss=np.load(files2[1])\n",
    "valacc=np.load(files2[2])\n",
    "valin=np.load(files2[3])\n",
    "valout=np.load(files2[4])\n",
    "valind=np.load(files2[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Nuova NN. Vengono caricati i files preparati con il training e associati ai rispettivi layers.\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(invar.shape[1],input_dim=invar.shape[1],activation='selu',kernel_regularizer=kr.l1(0.01)))\n",
    "model.add(Dense(round(invar.shape[1]*2/5),activation='selu',kernel_regularizer=kr.l1(0.01)))\n",
    "model.add(Dense(3,activation='softsign'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model.layers[0].set_weights([w0,b0])\n",
    "model.layers[1].set_weights([w1,b1])\n",
    "model.layers[2].set_weights([w2,b2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Viene fatta una run con tutte le stelle, si selezionano quali visualizzare direttamente nei grafici.\n",
    "\n",
    "out=model.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target:  NGC2243\n",
      "TP =  11 , TN =  74 , FP =  6 , FN =  2\n",
      "Precision =  0.6470588235294118 , Recall =  0.8461538461538461 , Accuracy =  0.9139784946236559\n",
      "F-score =  0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "dummyout=np_utils.to_categorical(valout)\n",
    "model2=Sequential()\n",
    "model2.add(Dense(invar.shape[1],input_dim=invar.shape[1],activation='selu',kernel_regularizer=kr.l1(0.01)))\n",
    "model2.add(Dense(round(invar.shape[1]*2/5),activation='selu',kernel_regularizer=kr.l1(0.01)))\n",
    "model2.add(Dense(3,activation='softsign'))\n",
    "model2.add(Dense(dummyout.shape[1],activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "model2._estimator_type='classifier'\n",
    "model2.layers[0].set_weights([w0,b0])\n",
    "model2.layers[1].set_weights([w1,b1])\n",
    "model2.layers[2].set_weights([w2,b2])\n",
    "model2.layers[3].set_weights([w3,b3])\n",
    "model2.classes_ = 0,1\n",
    "model2.dummy_='dummy'\n",
    "\n",
    "out2=model2.predict(valin)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(dummyout.argmax(axis=1),out2.argmax(axis=1))\n",
    "prec=cm[1,1]/(cm[1,1]+cm[0,1])\n",
    "recall=cm[1,1]/(cm[1,1]+cm[1,0])\n",
    "accur=(cm[1,1]+cm[0,0])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
    "fscore=cm[1,1]/(cm[1,1]+0.5*(cm[1,0]+cm[0,1]))\n",
    "print('Target: ',target)\n",
    "print('TP = ',cm[1,1],', TN = ',cm[0,0],', FP = ',cm[0,1],', FN = ',cm[1,0])\n",
    "print('Precision = ',prec,', Recall = ',recall,', Accuracy = ',accur)\n",
    "print('F-score = ',fscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3=model2.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import plot_partial_dependence\n",
    "elem = ['[Na1/Fe]','[Mg1/Fe]','[Al1/Fe]','[Ca1/Fe]','[Sc1/Fe]','[Sc2/Fe]','[Ti1/Fe]','[Va1/Fe]','[Cr1/Fe]','[Cr2/Fe]','[Fe2/Fe]','[Co1/Fe]','[Ni1/Fe]','[Y1/Fe]','[Fe/H]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(17, 15))\n",
    "ax.set_title(target,fontsize=28)\n",
    "mlp_disp = plot_partial_dependence(model2,dataset,target=1,features=[0,1,2,3,4,5],feature_names=elem,kind='both',ax=ax,percentiles=(0.00,1.00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(17, 15))\n",
    "ax.set_title(target,fontsize=28)\n",
    "mlp_disp = plot_partial_dependence(model2,dataset,target=1,features=[6,7,8,9,10,11],feature_names=elem,kind='both',ax=ax,percentiles=(0.00,1.00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(17, 5))\n",
    "ax.set_title(target,fontsize=28)\n",
    "mlp_disp = plot_partial_dependence(model2,dataset,target=1,features=[12,13,14],feature_names=elem,kind='both',ax=ax,percentiles=(0.00,1.00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  0 : --- 153.6030571460724 seconds ---\n",
      "Step  1 : --- 149.85823798179626 seconds ---\n",
      "Step  2 : --- 120.01253199577332 seconds ---\n",
      "Step  3 : --- 85.15466594696045 seconds ---\n",
      "Step  4 : --- 133.19202065467834 seconds ---\n",
      "Step  5 : --- 153.62458324432373 seconds ---\n",
      "Step  6 : --- 159.17383980751038 seconds ---\n",
      "--- 954.6199371814728 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "indel=[2,4,6,8,11,13,14]\n",
    "for i in range(len(indel)):\n",
    "    step = time.time()\n",
    "    fig, ax = plt.subplots(figsize=(17, 15))\n",
    "    feat=[]\n",
    "    for j in range(len(indel)):\n",
    "        if j==i:\n",
    "            pass\n",
    "        else:\n",
    "            feat.append((indel[i],indel[j]))\n",
    "    title='target, element'\n",
    "    title=title.replace('target',target)\n",
    "    title=title.replace('element',elem[indel[i]])\n",
    "    ax.set_title(title,fontsize=28)\n",
    "    mlp_disp = plot_partial_dependence(model2,dataset,features=feat,feature_names=elem,kind='average',ax=ax,percentiles=(0.00,1.00))\n",
    "    print('Step ',i,':',\"--- %s seconds ---\" % (time.time() - step))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
