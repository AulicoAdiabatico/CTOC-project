{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "import keras.regularizers as kr\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import keras.losses as ls\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "%matplotlib qt\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Target disponibili: 'NGC2243', 'NGC2420', 'Rup134', 'Trumpler20','Trumpler23'\n",
    "\n",
    "data=pd.read_csv('./Settings/Data/Default/DEFGBData.csv')\n",
    "err=pd.read_csv('./Settings/Data/DEFGBErr.csv')\n",
    "nancount=[]\n",
    "ind=[]\n",
    "for i in range(0,data.shape[0]):\n",
    "    nancount.append(data.iloc[i,12:].isnull().sum())\n",
    "    if nancount[i]==0:\n",
    "        ind.append(i)\n",
    "    else:\n",
    "        pass\n",
    "data=data.iloc[ind,:]\n",
    "target='Trumpler23'\n",
    "targetind=[]\n",
    "notargetind=[]\n",
    "for i in range(0,data.shape[0]):\n",
    "    if data.iloc[i,1]==target:\n",
    "        targetind.append(i)\n",
    "    else:\n",
    "        notargetind.append(i)\n",
    "tind=np.array(targetind)\n",
    "notind=np.array(notargetind)\n",
    "np.random.shuffle(tind)\n",
    "np.random.shuffle(notind)\n",
    "\n",
    "notvartrainind=notind[0:int(round(0.8*notind.shape[0]))]\n",
    "notvarvalind=notind[int(round(0.8*notind.shape[0])):notind.shape[0]]\n",
    "\n",
    "tvartrainind=tind[0:int(round(0.3*tind.shape[0]))]\n",
    "tvarvalind=tind[int(round(0.3*tind.shape[0])):tind.shape[0]]\n",
    "\n",
    "factor=int(notvartrainind.shape[0]/tvartrainind.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=data.values[:,12:].astype(float)\n",
    "datafei=data.values[:,9].astype(float)\n",
    "dataset=np.nan_to_num(dataset)\n",
    "datafei=np.nan_to_num(datafei)\n",
    "dataset=np.c_[dataset,datafei]\n",
    "errset=err.values\n",
    "errset=np.nan_to_num(errset)\n",
    "tvartrain=np.zeros([tvartrainind.shape[0]*factor,err.shape[1]])\n",
    "\n",
    "for i in range(0,tvartrainind.shape[0]):\n",
    "    for j in range(0,factor):\n",
    "        if j==0:\n",
    "            tvartrain[i*factor+j,:]=dataset[tvartrainind[i],:]\n",
    "        else:\n",
    "            tvartrain[i*factor+j,:]=dataset[tvartrainind[i],:]+np.multiply(np.random.normal(scale=(1/3),size=errset.shape[1]),errset[tvartrainind[i],:])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "asun=[6.24,7.60,6.47,6.34,3.15,3.15,4.95,3.93,5.64,5.64,7.50,7.50,4.99,6.22,2.21]\n",
    "for i in range(0,dataset.shape[0]):\n",
    "    for j in range(0,dataset.shape[1]-1):\n",
    "        if j==10:\n",
    "            pass\n",
    "        else:\n",
    "            dataset[i,j]=(dataset[i,j]-asun[j])-(dataset[i,10]-asun[10])\n",
    "for i in range(0,tvartrain.shape[0]):\n",
    "    for j in range(0,tvartrain.shape[1]-1):\n",
    "        if j==10:\n",
    "            pass\n",
    "        else:\n",
    "            tvartrain[i,j]=(tvartrain[i,j]-asun[j])-(tvartrain[i,10]-asun[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=np.delete(dataset,10,1)\n",
    "tvartrain=np.delete(tvartrain,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "invartrain=np.concatenate((dataset[np.ndarray.tolist(notvartrainind),:],tvartrain))\n",
    "outtrain=np.zeros(invartrain.shape[0])\n",
    "outtrain[notvartrainind.shape[0]:]=1.\n",
    "\n",
    "invarfit=np.concatenate((dataset[np.ndarray.tolist(notvarvalind),:],dataset[np.ndarray.tolist(tvarvalind),:]))\n",
    "outfit=np.zeros(invarfit.shape[0])\n",
    "outfit[(notvarvalind.shape[0]):]=1.\n",
    "invarind=np.concatenate((np.ndarray.tolist(notvarvalind),np.ndarray.tolist(tvarvalind)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Viene generato il file con le label degli oggetti.\n",
    "\n",
    "dummyout=np_utils.to_categorical(outtrain)\n",
    "\n",
    "dummytest=np_utils.to_categorical(outfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Modello di rete. La dimensione dei layer varia al variare della dimensione\n",
    "###dell'input. \n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(invartrain.shape[1],input_dim=invartrain.shape[1],activation='selu',kernel_regularizer=kr.l1(0.01)))\n",
    "model.add(Dense(round(invartrain.shape[1]*2/5),activation='selu',kernel_regularizer=kr.l1(0.04)))\n",
    "model.add(Dropout(0.85))\n",
    "model.add(Dense(2,activation='softsign'))\n",
    "model.add(Dense(dummyout.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 650 samples, validate on 90 samples\n",
      "Epoch 1/200\n",
      "650/650 [==============================] - 0s 245us/step - loss: 1.9489 - accuracy: 0.5708 - val_loss: 1.9040 - val_accuracy: 0.5444\n",
      "Epoch 2/200\n",
      "650/650 [==============================] - 0s 36us/step - loss: 1.8324 - accuracy: 0.6123 - val_loss: 1.7941 - val_accuracy: 0.5556\n",
      "Epoch 3/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 1.7344 - accuracy: 0.6000 - val_loss: 1.6854 - val_accuracy: 0.6000\n",
      "Epoch 4/200\n",
      "650/650 [==============================] - 0s 36us/step - loss: 1.6260 - accuracy: 0.6585 - val_loss: 1.5783 - val_accuracy: 0.6000\n",
      "Epoch 5/200\n",
      "650/650 [==============================] - 0s 38us/step - loss: 1.5384 - accuracy: 0.6231 - val_loss: 1.4864 - val_accuracy: 0.6222\n",
      "Epoch 6/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 1.4623 - accuracy: 0.6123 - val_loss: 1.3976 - val_accuracy: 0.6556\n",
      "Epoch 7/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 1.3785 - accuracy: 0.6385 - val_loss: 1.3328 - val_accuracy: 0.6222\n",
      "Epoch 8/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 1.3078 - accuracy: 0.6215 - val_loss: 1.2522 - val_accuracy: 0.6667\n",
      "Epoch 9/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 1.2427 - accuracy: 0.6185 - val_loss: 1.1842 - val_accuracy: 0.6778\n",
      "Epoch 10/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 1.1798 - accuracy: 0.6077 - val_loss: 1.1295 - val_accuracy: 0.6556\n",
      "Epoch 11/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 1.1149 - accuracy: 0.6200 - val_loss: 1.0637 - val_accuracy: 0.7111\n",
      "Epoch 12/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 1.0604 - accuracy: 0.5708 - val_loss: 1.0075 - val_accuracy: 0.7111\n",
      "Epoch 13/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 1.0108 - accuracy: 0.6108 - val_loss: 0.9715 - val_accuracy: 0.6667\n",
      "Epoch 14/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.9685 - accuracy: 0.5892 - val_loss: 0.9212 - val_accuracy: 0.6778\n",
      "Epoch 15/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.9152 - accuracy: 0.6200 - val_loss: 0.8811 - val_accuracy: 0.6889\n",
      "Epoch 16/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.8786 - accuracy: 0.6262 - val_loss: 0.8407 - val_accuracy: 0.6889\n",
      "Epoch 17/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 0.8441 - accuracy: 0.6062 - val_loss: 0.8002 - val_accuracy: 0.7111\n",
      "Epoch 18/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 0.8154 - accuracy: 0.5846 - val_loss: 0.7775 - val_accuracy: 0.7000\n",
      "Epoch 19/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.7918 - accuracy: 0.6138 - val_loss: 0.7584 - val_accuracy: 0.6889\n",
      "Epoch 20/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.7734 - accuracy: 0.6231 - val_loss: 0.7446 - val_accuracy: 0.6778\n",
      "Epoch 21/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 0.7496 - accuracy: 0.6338 - val_loss: 0.7350 - val_accuracy: 0.6444\n",
      "Epoch 22/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.7330 - accuracy: 0.6185 - val_loss: 0.7312 - val_accuracy: 0.6444\n",
      "Epoch 23/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 0.7229 - accuracy: 0.6077 - val_loss: 0.7194 - val_accuracy: 0.6444\n",
      "Epoch 24/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.7050 - accuracy: 0.6523 - val_loss: 0.6927 - val_accuracy: 0.6889\n",
      "Epoch 25/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 0.7009 - accuracy: 0.6000 - val_loss: 0.7048 - val_accuracy: 0.6222\n",
      "Epoch 26/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.7018 - accuracy: 0.5923 - val_loss: 0.7093 - val_accuracy: 0.6000\n",
      "Epoch 27/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 0.6907 - accuracy: 0.6138 - val_loss: 0.6706 - val_accuracy: 0.7000\n",
      "Epoch 28/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6891 - accuracy: 0.6246 - val_loss: 0.6640 - val_accuracy: 0.7000\n",
      "Epoch 29/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 0.6841 - accuracy: 0.6308 - val_loss: 0.6686 - val_accuracy: 0.6667\n",
      "Epoch 30/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6932 - accuracy: 0.5954 - val_loss: 0.6662 - val_accuracy: 0.6444\n",
      "Epoch 31/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6779 - accuracy: 0.6385 - val_loss: 0.6480 - val_accuracy: 0.7000\n",
      "Epoch 32/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6744 - accuracy: 0.6215 - val_loss: 0.6431 - val_accuracy: 0.7000\n",
      "Epoch 33/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.6702 - accuracy: 0.6354 - val_loss: 0.6475 - val_accuracy: 0.6778\n",
      "Epoch 34/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 0.6730 - accuracy: 0.6185 - val_loss: 0.6379 - val_accuracy: 0.6778\n",
      "Epoch 35/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6705 - accuracy: 0.6154 - val_loss: 0.6328 - val_accuracy: 0.7000\n",
      "Epoch 36/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6667 - accuracy: 0.6323 - val_loss: 0.6234 - val_accuracy: 0.7000\n",
      "Epoch 37/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.6732 - accuracy: 0.6123 - val_loss: 0.6245 - val_accuracy: 0.6889\n",
      "Epoch 38/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6556 - accuracy: 0.6631 - val_loss: 0.5806 - val_accuracy: 0.8000\n",
      "Epoch 39/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.6629 - accuracy: 0.6262 - val_loss: 0.6102 - val_accuracy: 0.7111\n",
      "Epoch 40/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6431 - accuracy: 0.6369 - val_loss: 0.6185 - val_accuracy: 0.6778\n",
      "Epoch 41/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6611 - accuracy: 0.6108 - val_loss: 0.6050 - val_accuracy: 0.7000\n",
      "Epoch 42/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.6590 - accuracy: 0.6231 - val_loss: 0.5814 - val_accuracy: 0.7111\n",
      "Epoch 43/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6519 - accuracy: 0.6369 - val_loss: 0.5868 - val_accuracy: 0.7111\n",
      "Epoch 44/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6380 - accuracy: 0.6569 - val_loss: 0.5645 - val_accuracy: 0.7111\n",
      "Epoch 45/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6495 - accuracy: 0.6138 - val_loss: 0.5937 - val_accuracy: 0.6778\n",
      "Epoch 46/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6446 - accuracy: 0.6323 - val_loss: 0.5570 - val_accuracy: 0.7111\n",
      "Epoch 47/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6405 - accuracy: 0.6600 - val_loss: 0.5421 - val_accuracy: 0.7333\n",
      "Epoch 48/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 0.6329 - accuracy: 0.6154 - val_loss: 0.5809 - val_accuracy: 0.6889\n",
      "Epoch 49/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 0.6355 - accuracy: 0.6200 - val_loss: 0.5274 - val_accuracy: 0.7889\n",
      "Epoch 50/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.6334 - accuracy: 0.6631 - val_loss: 0.5241 - val_accuracy: 0.7778\n",
      "Epoch 51/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6271 - accuracy: 0.6385 - val_loss: 0.5495 - val_accuracy: 0.7111\n",
      "Epoch 52/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6460 - accuracy: 0.6400 - val_loss: 0.5064 - val_accuracy: 0.8000\n",
      "Epoch 53/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6302 - accuracy: 0.6462 - val_loss: 0.4949 - val_accuracy: 0.8222\n",
      "Epoch 54/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.6273 - accuracy: 0.6477 - val_loss: 0.5442 - val_accuracy: 0.7111\n",
      "Epoch 55/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6408 - accuracy: 0.6446 - val_loss: 0.4948 - val_accuracy: 0.8000\n",
      "Epoch 56/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.6240 - accuracy: 0.6462 - val_loss: 0.5170 - val_accuracy: 0.7222\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650/650 [==============================] - 0s 34us/step - loss: 0.6416 - accuracy: 0.6415 - val_loss: 0.4903 - val_accuracy: 0.8111\n",
      "Epoch 58/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6262 - accuracy: 0.6415 - val_loss: 0.5012 - val_accuracy: 0.7778\n",
      "Epoch 59/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.6193 - accuracy: 0.6477 - val_loss: 0.4933 - val_accuracy: 0.8000\n",
      "Epoch 60/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6211 - accuracy: 0.6292 - val_loss: 0.4960 - val_accuracy: 0.7778\n",
      "Epoch 61/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.5890 - accuracy: 0.6492 - val_loss: 0.5044 - val_accuracy: 0.7444\n",
      "Epoch 62/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6097 - accuracy: 0.6538 - val_loss: 0.4829 - val_accuracy: 0.8000\n",
      "Epoch 63/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6118 - accuracy: 0.6554 - val_loss: 0.4641 - val_accuracy: 0.8556\n",
      "Epoch 64/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6124 - accuracy: 0.6585 - val_loss: 0.4783 - val_accuracy: 0.8000\n",
      "Epoch 65/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6328 - accuracy: 0.6185 - val_loss: 0.4851 - val_accuracy: 0.7667\n",
      "Epoch 66/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6064 - accuracy: 0.6554 - val_loss: 0.4676 - val_accuracy: 0.8111\n",
      "Epoch 67/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6174 - accuracy: 0.6323 - val_loss: 0.4440 - val_accuracy: 0.8444\n",
      "Epoch 68/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6141 - accuracy: 0.6554 - val_loss: 0.4590 - val_accuracy: 0.8444\n",
      "Epoch 69/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6069 - accuracy: 0.6631 - val_loss: 0.4388 - val_accuracy: 0.8444\n",
      "Epoch 70/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6005 - accuracy: 0.6554 - val_loss: 0.4658 - val_accuracy: 0.8000\n",
      "Epoch 71/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6180 - accuracy: 0.6508 - val_loss: 0.4349 - val_accuracy: 0.8444\n",
      "Epoch 72/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6117 - accuracy: 0.6538 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6176 - accuracy: 0.6415 - val_loss: 0.4305 - val_accuracy: 0.8444\n",
      "Epoch 74/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5986 - accuracy: 0.6831 - val_loss: 0.4394 - val_accuracy: 0.8556\n",
      "Epoch 75/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6221 - accuracy: 0.6600 - val_loss: 0.4159 - val_accuracy: 0.8556\n",
      "Epoch 76/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6137 - accuracy: 0.6554 - val_loss: 0.4415 - val_accuracy: 0.8444\n",
      "Epoch 77/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6053 - accuracy: 0.6354 - val_loss: 0.4309 - val_accuracy: 0.8444\n",
      "Epoch 78/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5959 - accuracy: 0.6415 - val_loss: 0.4474 - val_accuracy: 0.8444\n",
      "Epoch 79/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.6189 - accuracy: 0.6431 - val_loss: 0.4557 - val_accuracy: 0.8000\n",
      "Epoch 80/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5836 - accuracy: 0.6754 - val_loss: 0.4134 - val_accuracy: 0.8444\n",
      "Epoch 81/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.6094 - accuracy: 0.6585 - val_loss: 0.4182 - val_accuracy: 0.8444\n",
      "Epoch 82/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6028 - accuracy: 0.6754 - val_loss: 0.4117 - val_accuracy: 0.8556\n",
      "Epoch 83/200\n",
      "650/650 [==============================] - 0s 31us/step - loss: 0.6026 - accuracy: 0.6708 - val_loss: 0.4151 - val_accuracy: 0.8444\n",
      "Epoch 84/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6007 - accuracy: 0.6492 - val_loss: 0.4294 - val_accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6196 - accuracy: 0.6508 - val_loss: 0.3978 - val_accuracy: 0.8444\n",
      "Epoch 86/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6072 - accuracy: 0.6831 - val_loss: 0.4192 - val_accuracy: 0.8444\n",
      "Epoch 87/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6113 - accuracy: 0.6738 - val_loss: 0.4098 - val_accuracy: 0.8667\n",
      "Epoch 88/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6134 - accuracy: 0.6708 - val_loss: 0.4290 - val_accuracy: 0.8444\n",
      "Epoch 89/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5824 - accuracy: 0.6785 - val_loss: 0.4059 - val_accuracy: 0.8556\n",
      "Epoch 90/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5896 - accuracy: 0.6938 - val_loss: 0.4034 - val_accuracy: 0.8556\n",
      "Epoch 91/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5928 - accuracy: 0.7015 - val_loss: 0.3960 - val_accuracy: 0.8667\n",
      "Epoch 92/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5957 - accuracy: 0.7015 - val_loss: 0.4159 - val_accuracy: 0.8556\n",
      "Epoch 93/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.6067 - accuracy: 0.6492 - val_loss: 0.3880 - val_accuracy: 0.8667\n",
      "Epoch 94/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5808 - accuracy: 0.6969 - val_loss: 0.3859 - val_accuracy: 0.8667\n",
      "Epoch 95/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5801 - accuracy: 0.6831 - val_loss: 0.3953 - val_accuracy: 0.8667\n",
      "Epoch 96/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5997 - accuracy: 0.6877 - val_loss: 0.3865 - val_accuracy: 0.8667\n",
      "Epoch 97/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5860 - accuracy: 0.6877 - val_loss: 0.4109 - val_accuracy: 0.8556\n",
      "Epoch 98/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5839 - accuracy: 0.7031 - val_loss: 0.3619 - val_accuracy: 0.8667\n",
      "Epoch 99/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5873 - accuracy: 0.6800 - val_loss: 0.4206 - val_accuracy: 0.8444\n",
      "Epoch 100/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5768 - accuracy: 0.6892 - val_loss: 0.3727 - val_accuracy: 0.8667\n",
      "Epoch 101/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.5633 - accuracy: 0.7046 - val_loss: 0.4090 - val_accuracy: 0.8556\n",
      "Epoch 102/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5704 - accuracy: 0.6969 - val_loss: 0.3641 - val_accuracy: 0.8667\n",
      "Epoch 103/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5968 - accuracy: 0.6846 - val_loss: 0.3945 - val_accuracy: 0.8556\n",
      "Epoch 104/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5672 - accuracy: 0.6846 - val_loss: 0.3768 - val_accuracy: 0.8778\n",
      "Epoch 105/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.5858 - accuracy: 0.6862 - val_loss: 0.3548 - val_accuracy: 0.8667\n",
      "Epoch 106/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 0.5560 - accuracy: 0.7200 - val_loss: 0.3719 - val_accuracy: 0.8778\n",
      "Epoch 107/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6014 - accuracy: 0.6723 - val_loss: 0.3763 - val_accuracy: 0.8778\n",
      "Epoch 108/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.5819 - accuracy: 0.6785 - val_loss: 0.3725 - val_accuracy: 0.8778\n",
      "Epoch 109/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5954 - accuracy: 0.6862 - val_loss: 0.3545 - val_accuracy: 0.8778\n",
      "Epoch 110/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5509 - accuracy: 0.7123 - val_loss: 0.3827 - val_accuracy: 0.8667\n",
      "Epoch 111/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5749 - accuracy: 0.6908 - val_loss: 0.3456 - val_accuracy: 0.8778\n",
      "Epoch 112/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5843 - accuracy: 0.6938 - val_loss: 0.3671 - val_accuracy: 0.8778\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650/650 [==============================] - 0s 33us/step - loss: 0.5878 - accuracy: 0.6769 - val_loss: 0.3627 - val_accuracy: 0.8778\n",
      "Epoch 114/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5662 - accuracy: 0.7015 - val_loss: 0.3548 - val_accuracy: 0.8778\n",
      "Epoch 115/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5629 - accuracy: 0.6785 - val_loss: 0.3893 - val_accuracy: 0.8556\n",
      "Epoch 116/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5500 - accuracy: 0.7077 - val_loss: 0.3646 - val_accuracy: 0.8778\n",
      "Epoch 117/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5753 - accuracy: 0.6846 - val_loss: 0.3485 - val_accuracy: 0.8778\n",
      "Epoch 118/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5614 - accuracy: 0.7015 - val_loss: 0.3547 - val_accuracy: 0.8778\n",
      "Epoch 119/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5658 - accuracy: 0.6892 - val_loss: 0.3615 - val_accuracy: 0.8778\n",
      "Epoch 120/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5674 - accuracy: 0.6754 - val_loss: 0.3472 - val_accuracy: 0.8778\n",
      "Epoch 121/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.6039 - accuracy: 0.6615 - val_loss: 0.3380 - val_accuracy: 0.8778\n",
      "Epoch 122/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5571 - accuracy: 0.7092 - val_loss: 0.3800 - val_accuracy: 0.8778\n",
      "Epoch 123/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 0.5564 - accuracy: 0.6877 - val_loss: 0.3429 - val_accuracy: 0.8778\n",
      "Epoch 124/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5566 - accuracy: 0.7077 - val_loss: 0.3367 - val_accuracy: 0.8778\n",
      "Epoch 125/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5939 - accuracy: 0.6862 - val_loss: 0.3569 - val_accuracy: 0.8778\n",
      "Epoch 126/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5633 - accuracy: 0.6969 - val_loss: 0.3593 - val_accuracy: 0.8778\n",
      "Epoch 127/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5893 - accuracy: 0.6862 - val_loss: 0.3392 - val_accuracy: 0.8778\n",
      "Epoch 128/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5540 - accuracy: 0.6969 - val_loss: 0.3444 - val_accuracy: 0.8778\n",
      "Epoch 129/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5452 - accuracy: 0.7138 - val_loss: 0.3657 - val_accuracy: 0.8778\n",
      "Epoch 130/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5477 - accuracy: 0.7015 - val_loss: 0.3505 - val_accuracy: 0.8778\n",
      "Epoch 131/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5632 - accuracy: 0.6815 - val_loss: 0.3615 - val_accuracy: 0.8778\n",
      "Epoch 132/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5467 - accuracy: 0.7246 - val_loss: 0.3272 - val_accuracy: 0.8778\n",
      "Epoch 133/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5387 - accuracy: 0.7000 - val_loss: 0.3397 - val_accuracy: 0.8778\n",
      "Epoch 134/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5621 - accuracy: 0.7062 - val_loss: 0.3289 - val_accuracy: 0.8778\n",
      "Epoch 135/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5663 - accuracy: 0.7000 - val_loss: 0.3418 - val_accuracy: 0.8778\n",
      "Epoch 136/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5685 - accuracy: 0.6923 - val_loss: 0.3498 - val_accuracy: 0.8778\n",
      "Epoch 137/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5395 - accuracy: 0.7292 - val_loss: 0.3368 - val_accuracy: 0.8778\n",
      "Epoch 138/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5754 - accuracy: 0.6862 - val_loss: 0.3381 - val_accuracy: 0.8778\n",
      "Epoch 139/200\n",
      "650/650 [==============================] - 0s 36us/step - loss: 0.5631 - accuracy: 0.7046 - val_loss: 0.3351 - val_accuracy: 0.8778\n",
      "Epoch 140/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 0.5986 - accuracy: 0.6646 - val_loss: 0.3378 - val_accuracy: 0.8778\n",
      "Epoch 141/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5643 - accuracy: 0.6769 - val_loss: 0.3346 - val_accuracy: 0.8778\n",
      "Epoch 142/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5763 - accuracy: 0.6785 - val_loss: 0.3198 - val_accuracy: 0.8778\n",
      "Epoch 143/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5327 - accuracy: 0.7123 - val_loss: 0.3459 - val_accuracy: 0.8778\n",
      "Epoch 144/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5441 - accuracy: 0.6985 - val_loss: 0.3264 - val_accuracy: 0.8778\n",
      "Epoch 145/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5628 - accuracy: 0.7108 - val_loss: 0.3305 - val_accuracy: 0.8778\n",
      "Epoch 146/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.5550 - accuracy: 0.6754 - val_loss: 0.3530 - val_accuracy: 0.8778\n",
      "Epoch 147/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5605 - accuracy: 0.6892 - val_loss: 0.3218 - val_accuracy: 0.8778\n",
      "Epoch 148/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5534 - accuracy: 0.7000 - val_loss: 0.3337 - val_accuracy: 0.8778\n",
      "Epoch 149/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5609 - accuracy: 0.6754 - val_loss: 0.3383 - val_accuracy: 0.8778\n",
      "Epoch 150/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5599 - accuracy: 0.7108 - val_loss: 0.3276 - val_accuracy: 0.8778\n",
      "Epoch 151/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5706 - accuracy: 0.6800 - val_loss: 0.3287 - val_accuracy: 0.8778\n",
      "Epoch 152/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5683 - accuracy: 0.6985 - val_loss: 0.3238 - val_accuracy: 0.8778\n",
      "Epoch 153/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5426 - accuracy: 0.7185 - val_loss: 0.3190 - val_accuracy: 0.8778\n",
      "Epoch 154/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5750 - accuracy: 0.6938 - val_loss: 0.3275 - val_accuracy: 0.8778\n",
      "Epoch 155/200\n",
      "650/650 [==============================] - 0s 31us/step - loss: 0.5703 - accuracy: 0.6908 - val_loss: 0.3067 - val_accuracy: 0.8889\n",
      "Epoch 156/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.5607 - accuracy: 0.6954 - val_loss: 0.3372 - val_accuracy: 0.8778\n",
      "Epoch 157/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5553 - accuracy: 0.6738 - val_loss: 0.3288 - val_accuracy: 0.8778\n",
      "Epoch 158/200\n",
      "650/650 [==============================] - 0s 31us/step - loss: 0.5461 - accuracy: 0.6954 - val_loss: 0.3407 - val_accuracy: 0.8778\n",
      "Epoch 159/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5558 - accuracy: 0.7092 - val_loss: 0.3164 - val_accuracy: 0.8778\n",
      "Epoch 160/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.5537 - accuracy: 0.6708 - val_loss: 0.3589 - val_accuracy: 0.8778\n",
      "Epoch 161/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5683 - accuracy: 0.6954 - val_loss: 0.3080 - val_accuracy: 0.8889\n",
      "Epoch 162/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5649 - accuracy: 0.6923 - val_loss: 0.3306 - val_accuracy: 0.8778\n",
      "Epoch 163/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.5461 - accuracy: 0.6969 - val_loss: 0.3172 - val_accuracy: 0.8778\n",
      "Epoch 164/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5399 - accuracy: 0.7200 - val_loss: 0.3121 - val_accuracy: 0.8778\n",
      "Epoch 165/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5782 - accuracy: 0.6862 - val_loss: 0.3157 - val_accuracy: 0.8778\n",
      "Epoch 166/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5428 - accuracy: 0.6862 - val_loss: 0.3585 - val_accuracy: 0.8556\n",
      "Epoch 167/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5666 - accuracy: 0.6938 - val_loss: 0.2993 - val_accuracy: 0.9000\n",
      "Epoch 168/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.5626 - accuracy: 0.6815 - val_loss: 0.3299 - val_accuracy: 0.8778\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650/650 [==============================] - 0s 33us/step - loss: 0.5387 - accuracy: 0.7031 - val_loss: 0.3219 - val_accuracy: 0.8778\n",
      "Epoch 170/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.5492 - accuracy: 0.6877 - val_loss: 0.3184 - val_accuracy: 0.8778\n",
      "Epoch 171/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5503 - accuracy: 0.6938 - val_loss: 0.3178 - val_accuracy: 0.8778\n",
      "Epoch 172/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5595 - accuracy: 0.6954 - val_loss: 0.3120 - val_accuracy: 0.8778\n",
      "Epoch 173/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5658 - accuracy: 0.6754 - val_loss: 0.3074 - val_accuracy: 0.8778\n",
      "Epoch 174/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5411 - accuracy: 0.7092 - val_loss: 0.3223 - val_accuracy: 0.8778\n",
      "Epoch 175/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5468 - accuracy: 0.6938 - val_loss: 0.3212 - val_accuracy: 0.8778\n",
      "Epoch 176/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5469 - accuracy: 0.7123 - val_loss: 0.3177 - val_accuracy: 0.8778\n",
      "Epoch 177/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5409 - accuracy: 0.7108 - val_loss: 0.3267 - val_accuracy: 0.8778\n",
      "Epoch 178/200\n",
      "650/650 [==============================] - 0s 31us/step - loss: 0.5411 - accuracy: 0.7108 - val_loss: 0.3236 - val_accuracy: 0.8778\n",
      "Epoch 179/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.5500 - accuracy: 0.7123 - val_loss: 0.3180 - val_accuracy: 0.8778\n",
      "Epoch 180/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5687 - accuracy: 0.6985 - val_loss: 0.3126 - val_accuracy: 0.8778\n",
      "Epoch 181/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5711 - accuracy: 0.7000 - val_loss: 0.2931 - val_accuracy: 0.9000\n",
      "Epoch 182/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5446 - accuracy: 0.7154 - val_loss: 0.3180 - val_accuracy: 0.8778\n",
      "Epoch 183/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5573 - accuracy: 0.6877 - val_loss: 0.3080 - val_accuracy: 0.8778\n",
      "Epoch 184/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 0.5632 - accuracy: 0.6985 - val_loss: 0.3174 - val_accuracy: 0.8778\n",
      "Epoch 185/200\n",
      "650/650 [==============================] - 0s 35us/step - loss: 0.5585 - accuracy: 0.7077 - val_loss: 0.3162 - val_accuracy: 0.8778\n",
      "Epoch 186/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5622 - accuracy: 0.6862 - val_loss: 0.3283 - val_accuracy: 0.8778\n",
      "Epoch 187/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5494 - accuracy: 0.7000 - val_loss: 0.3111 - val_accuracy: 0.8778\n",
      "Epoch 188/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5207 - accuracy: 0.7031 - val_loss: 0.3321 - val_accuracy: 0.8778\n",
      "Epoch 189/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5572 - accuracy: 0.6831 - val_loss: 0.3027 - val_accuracy: 0.8778\n",
      "Epoch 190/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5531 - accuracy: 0.6862 - val_loss: 0.3029 - val_accuracy: 0.8889\n",
      "Epoch 191/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5450 - accuracy: 0.7292 - val_loss: 0.3194 - val_accuracy: 0.8778\n",
      "Epoch 192/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5476 - accuracy: 0.7031 - val_loss: 0.3055 - val_accuracy: 0.8778\n",
      "Epoch 193/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5788 - accuracy: 0.6831 - val_loss: 0.3206 - val_accuracy: 0.8778\n",
      "Epoch 194/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5360 - accuracy: 0.6969 - val_loss: 0.3116 - val_accuracy: 0.8778\n",
      "Epoch 195/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5434 - accuracy: 0.7123 - val_loss: 0.2996 - val_accuracy: 0.8778\n",
      "Epoch 196/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.5427 - accuracy: 0.6954 - val_loss: 0.3083 - val_accuracy: 0.8778\n",
      "Epoch 197/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5238 - accuracy: 0.7185 - val_loss: 0.3166 - val_accuracy: 0.8778\n",
      "Epoch 198/200\n",
      "650/650 [==============================] - 0s 34us/step - loss: 0.5625 - accuracy: 0.7000 - val_loss: 0.3014 - val_accuracy: 0.8778\n",
      "Epoch 199/200\n",
      "650/650 [==============================] - 0s 32us/step - loss: 0.5604 - accuracy: 0.7138 - val_loss: 0.2897 - val_accuracy: 0.9000\n",
      "Epoch 200/200\n",
      "650/650 [==============================] - 0s 33us/step - loss: 0.5615 - accuracy: 0.6969 - val_loss: 0.3136 - val_accuracy: 0.8778\n"
     ]
    }
   ],
   "source": [
    "###Training\n",
    "ep=200\n",
    "history=model.fit(invartrain,dummyout,validation_data=(invarfit,dummytest),epochs=ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.3554491148545192, 0.9138461351394653],\n",
       " [0.31357346044646367, 0.8777777552604675])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Valutazione del training fatto.\n",
    "\n",
    "trainmse=model.evaluate(invartrain,dummyout,verbose=0)\n",
    "testmse=model.evaluate(invarfit,dummytest,verbose=0)\n",
    "trainmse,testmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Plot delle Loss\n",
    "\n",
    "plt.close()\n",
    "plt.title('Train vs Test Loss Functions')\n",
    "plt.xlabel('Ages',fontsize='large')\n",
    "plt.ylabel('Loss',fontsize='large')\n",
    "plt.plot(history.history['loss'], label='Train set')\n",
    "plt.plot(history.history['val_loss'], label='Test set')\n",
    "plt.legend(fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Plot della accuracy\n",
    "\n",
    "plt.close()\n",
    "plt.title('Accuracy',fontsize='large')\n",
    "plt.xlabel('Ages',fontsize='large')\n",
    "plt.ylabel('Accuracy',fontsize='large')\n",
    "plt.scatter(list(range(1,ep+1)),history.history['val_accuracy'],marker='.',color='blue',facecolor='None',label='accuracy')\n",
    "\n",
    "plt.legend(fontsize='large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Plot combinato di loss e accuracy\n",
    "\n",
    "plt.close()\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, sharex=True)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "ax1.plot(history.history['loss'], label='Training set')\n",
    "ax1.plot(history.history['val_loss'], label='Validation set')\n",
    "ax2.scatter(list(range(1,ep+1)),history.history['val_accuracy'],marker='.',color='blue',facecolor='None',label='Validation accuracy')\n",
    "ax1.title.set_text('Training vs Validation Loss funtions & Accuracy, GB Stars')\n",
    "plt.xlabel('Epochs',fontsize='large')\n",
    "ax1.legend(loc='upper right')\n",
    "ax2.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Vengono salvati i weights e bias in 6 file distinti, che verranno caricati nel prossimo file:\n",
    "###GBFinalNN. NB sono disponibili i weights trovati da me nella cartella FixedWeights.\n",
    "path=\"./Settings/Weights/target/prova\"\n",
    "path=path.replace('target',target)\n",
    "files=['/gbl0.npy','/gbl0bias.npy','/gbl1.npy','/gbl1bias.npy','/gbl2.npy','/gbl2bias.npy','/gbl3.npy','/gbl3bias.npy']\n",
    "for i in range(len(files)):\n",
    "    files[i]=path+files[i]\n",
    "\n",
    "fixedw=model.get_weights()\n",
    "fixedw=model.get_weights()\n",
    "l0=model.layers[0].get_weights()\n",
    "np.save(files[0],l0[0])\n",
    "np.save(files[1],l0[1])\n",
    "l1=model.layers[1].get_weights()\n",
    "np.save(files[2],l1[0])\n",
    "np.save(files[3],l1[1])\n",
    "l2=model.layers[3].get_weights()\n",
    "np.save(files[4],l2[0])\n",
    "np.save(files[5],l2[1])\n",
    "l3=model.layers[4].get_weights()\n",
    "np.save(files[6],l3[0])\n",
    "np.save(files[7],l3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Viene salvato il validation set e i dati dei plot\n",
    "path2=\"./Settings/target/prova\"\n",
    "path2=path2.replace('target',target)\n",
    "files2=['/vallossgb.npy','/trainlossgb.npy','/valaccuracygb.npy','/valsetinputgb.npy','/valsetoutputgb.npy','/valindgb.npy']\n",
    "for i in range(len(files2)):\n",
    "    files2[i]=path2+files2[i]\n",
    "    \n",
    "np.save(files2[0],history.history['val_loss'])\n",
    "np.save(files2[1],history.history['loss'])\n",
    "np.save(files2[2],history.history['val_accuracy'])\n",
    "np.save(files2[3],invarfit)\n",
    "np.save(files2[4],outfit)\n",
    "np.save(files2[5],invarind)\n",
    "\n",
    "#np.save(files2[],history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
